{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2025 Symbolic regression Monod paper\n",
    "# Posttreatment of symbolic regression equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#import itertools\n",
    "from sympy import *\n",
    "from IPython.display import display # to display symbolic expressions\n",
    "\n",
    "import os\n",
    "#import string\n",
    "#from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.core.numbers import Integer, NegativeOne\n",
    "from sympy.functions.elementary.complexes import sign\n",
    "from sympy.physics.units.quantities import Quantity\n",
    "from sympy.solvers.ode import constantsimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, C, n, S = symbols(\"t C n S\", nonegative=True)\n",
    "U, F, C1, C2 = symbols(\"U F C1 C2\", positive=True)\n",
    "Nc, gmax, S0 = symbols(\"Nc gmax S0\", positive=True)\n",
    "nu = symbols(\"nu\", real=True)\n",
    "\n",
    "symbols_dict = {\"C\": C,\n",
    "                \"F\": F,\n",
    "                \"n\": n,\n",
    "                \"S\": S,\n",
    "                \"t\": t,\n",
    "                \"U\": U,\n",
    "                \"C1\": C1,\n",
    "                \"C2\": C2,\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_a_remarkable_number(a):\n",
    "    return not isinstance(a, NegativeOne) and isinstance(a, Number)\n",
    "\n",
    "def contains_remarkable_number(expr):\n",
    "    \n",
    "    for a in list(expr.atoms()):\n",
    "        if is_a_remarkable_number(a):\n",
    "            return True\n",
    "            \n",
    "    return False\n",
    "\n",
    "def replace_numbers_by_Ks(expr):\n",
    "    x = 1\n",
    "    for a in preorder_traversal(expr):\n",
    "        if is_a_remarkable_number(a):\n",
    "            expr = expr.subs(a, sign(a) * Quantity(\"K{}\".format(x)))\n",
    "            x +=1\n",
    "            \n",
    "    return expr\n",
    "\n",
    "def count_Quantitys(expr):\n",
    "\n",
    "    out = 0\n",
    "    for a in preorder_traversal(expr):\n",
    "        if isinstance(a, Quantity):\n",
    "            out += 1\n",
    "            \n",
    "    return out\n",
    "\n",
    "def count_parameters(expr, Kxpr=False):\n",
    "    \n",
    "    while contains_remarkable_number(expr):\n",
    "        expr = replace_numbers_by_Ks(expr)\n",
    "        expr = constantsimp(expr, [i for i in expr.atoms(Quantity)]) # simplify constants\n",
    "        out = count_Quantitys(expr)\n",
    "    if Kxpr:\n",
    "        out = (out, expr)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive SR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfiles = []\n",
    "for root, dirs, files in os.walk(\"{}/data/\".format(cwd)):\n",
    "    for file in files:\n",
    "        if \"Rs0i\" in file:\n",
    "            allfiles.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in allfiles:\n",
    "    \n",
    "    name = file[-file[::-1].index(\"/\"):-file[::-1].index(\".\")-1]\n",
    "    df = pd.read_csv(file)\n",
    "    concs = sorted(list(df[\"C\"].unique()))\n",
    "    conc_dict = dict(zip(concs, np.array(np.arange(len(concs)) % 2, dtype=bool)))\n",
    "    df[\"C_filter\"] = df[\"C\"].apply(lambda x: conc_dict[x])\n",
    "    \n",
    "    tst_data = df[df[\"C_filter\"]].copy()\n",
    "    tst_data.drop(\"C_filter\", axis = 1, inplace = True)\n",
    "    tst_data.to_csv(\"{}/data_test/{}.csv\".format(cwd, name), index=False)\n",
    "    \n",
    "    trn_data = df[~df[\"C_filter\"]].copy()\n",
    "    trn_data.drop(\"C_filter\", axis = 1, inplace = True)\n",
    "    trn_data.to_csv(\"{}/data_train/{}.csv\".format(cwd, name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run naive SR on command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posttreatment of SR halls-of-fame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfiles = []\n",
    "for root, dirs, files in os.walk(\"{}/SR_Rs0_naiveSR/\".format(cwd)):\n",
    "    if \"Rs0i\" in root:\n",
    "        for file in files:\n",
    "            if file == \"hall_of_fame.csv\":\n",
    "                allfiles.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, file in enumerate(allfiles):\n",
    "    \n",
    "    name = file[:-file[::-1].index(\"/\")-1]\n",
    "    feat = name[:-name[::-1].index(\"/\")-1]\n",
    "    name = name[-name[::-1].index(\"-\"):] # e.g. \"Rs0i6\"\n",
    "\n",
    "    data = pd.read_csv(file, index_col=False )\n",
    "    eqns = \"_\".join(data[\"Equation\"])\n",
    "    feat = 2 * int(\"F\" in eqns) + int(\"U\" in eqns) # {\"n_C\": 0, \"n_C_U\": 1, \"F_C\": 2, \"F_C_U\": 3,}\n",
    "    \n",
    "    trn_data, tst_data = pd.read_csv(\"{}/data_train/{}.csv\".format(cwd, name)), pd.read_csv(\"{}/data_test/{}.csv\".format(cwd, name))\n",
    "    trn_rhos, tst_rhos = trn_data[\"rho\"], tst_data[\"rho\"]\n",
    "    trn_rho_bar, tst_rho_bar = trn_rhos.mean(), tst_rhos.mean()\n",
    "    \n",
    "    eqns = data[\"Equation\"].apply(lambda x: x.replace(\"^\", \"**\") )\n",
    "    \n",
    "    exprs, csts_counts, trn_RSSs, tst_RSSs = [], [], [], []\n",
    "    for i, expr in enumerate(eqns):\n",
    "        expr = simplify(parse_expr(expr, symbols_dict))\n",
    "        exprs.append(expr)\n",
    "        csts_counts.append( count_parameters(expr) ) # count constants in each model\n",
    "        # eval error\n",
    "        trn_rho_hats = trn_data[[\"C\", \"n\", \"F\", \"U\"]].apply(lambda x: expr.evalf(subs = {C: x.iloc[0], n: x.iloc[1], F: x.iloc[2], U: x.iloc[3],}), axis=1)\n",
    "        tst_rho_hats = tst_data[[\"C\", \"n\", \"F\", \"U\"]].apply(lambda x: expr.evalf(subs = {C: x.iloc[0], n: x.iloc[1], F: x.iloc[2], U: x.iloc[3],}), axis=1)\n",
    "        trn_RSSs.append( np.sum( (trn_rhos - trn_rho_hats)**2 ) )\n",
    "        tst_RSSs.append( np.sum( (tst_rhos - tst_rho_hats)**2 ) )\n",
    "    \n",
    "    data = pd.concat([data, pd.DataFrame({\"strn\": name, \"feat\": feat, \"csts\": csts_counts, \"expr\": exprs, \"RSS_trn\": trn_RSSs, \"RSS_tst\": tst_RSSs}, ), ], axis=1)\n",
    "    data[\"R2_trn\"] = 1 - data[\"RSS_trn\"] / np.sum( (trn_rhos - trn_rho_bar)**2 )\n",
    "    data[\"R2_tst\"] = 1 - data[\"RSS_tst\"] / np.sum( (tst_rhos - tst_rho_bar)**2 )\n",
    "\n",
    "    print(f / len(allfiles), end=\"\\r\")\n",
    "    alldata = data if f == 0 else pd.concat([alldata, data], axis = 0, ignore_index = True,)\n",
    "\n",
    "alldata.to_csv(\"{}/SR_Rs0_naiveSR/Rs0.csv\".format(cwd), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of feature-set impact on SR Fig. 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"{}/SR_Rs0_naiveSR/Rs0.csv\".format(cwd), )\n",
    "df[[\"train_R2\", \"test_R2\"]] = df[[\"R2_trn\", \"R2_tst\"]]\n",
    "df.sort_values([\"csts\", \"feat\", \"test_R2\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "step = 0.2\n",
    "\n",
    "title = \"Random Forest regression on experimental data\"\n",
    "\n",
    "abcisses = \"model complexity: number of parameters\"\n",
    "ordonnees = r\"performance: coefficient of determination $R^2$\"\n",
    "couleurs = \"feature set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"{}/SR_naive_results/Rs0.csv\".format(cwd,))\n",
    "df[\"test_R2\"] = 1 - df[\"Loss\"]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train scores\n",
    "Y = df[[\"csts\", \"feat\"]].apply(lambda x: \"_\".join(str(k) for k in x.values), axis=1)\n",
    "Y = df[[\"train_R2\", \"csts\", \"feat\"]].groupby(Y).median()\n",
    "X = Y[\"csts\"] - 1 + ( Y[\"feat\"] - 3/2 ) * step\n",
    "Y = Y[\"train_R2\"]\n",
    "\n",
    "# test score boxplots\n",
    "df.rename(columns = {\"csts\": abcisses, \"feat\": couleurs, \"test_R2\": ordonnees}, inplace=True) # variable-names\n",
    "df[couleurs] = df[couleurs].apply(lambda x: {0: r\"{$C$, $N$}\",\n",
    "                                             1: r\"{$C$, $N$, $t$}\",\n",
    "                                             2: r\"{$C$, $N_c$}\",\n",
    "                                             3: r\"{$C$, $N_c$, $t$}\",\n",
    "                                             }[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,5), constrained_layout=True)\n",
    "gs = fig.add_gridspec(1, 1)\n",
    "\n",
    "ax = fig.add_subplot(gs[:,:],)\n",
    "ax = sns.boxplot(data=df, y=ordonnees, x=abcisses, hue=couleurs, showfliers=False, ax=ax, palette=\"tab10\", )\n",
    "ax.scatter(X, Y, marker=\"x\", c=\"k\", zorder=4,)\n",
    "\n",
    "ax.set(xlim=(-0.5,16.5), ylim=(0,1), )\n",
    "#ax.set_title(title)\n",
    "\n",
    "### SAVING\n",
    "name = \"{}/plot/SR_boxplot_Rs0.pdf\".format(cwd,)\n",
    "#plt.savefig(name, facecolor='w', edgecolor='w', transparent=False, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"Rs0\"\n",
    "cwd2 = # location of the SR outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalocation = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfiles = []\n",
    "for root, dirs, files in os.walk(cwd2):\n",
    "    if \"test\" in root:\n",
    "        continue\n",
    "    for file in files:\n",
    "        if file == \"hall_of_fame.csv\":\n",
    "            allfiles.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, file in enumerate(allfiles):\n",
    "    \n",
    "    name = file[:-file[::-1].index(\"/\")-1]\n",
    "    feat = name[:-name[::-1].index(\"/\")-1]\n",
    "    name = name[-name[::-1].index(\"-\"):] # e.g. \"Rs0i6\"\n",
    "    feat = feat[-feat[::-1].index(\"/\"):]\n",
    "    template = {\"final_model_1\": 0, \"final_model_2\": 1, \"final_model_3\": 2, \"no_template\": 0, \"template_1\": 1, \"template_2\": 2, }[feat]\n",
    "    \n",
    "    eqns = pd.read_csv(file, index_col=False )\n",
    "    Loss = eqns[\"Loss\"]\n",
    "    eqns[\"Equation\"] = eqns[\"Equation\"].apply(lambda x: x.replace(\"^\", \"**\") )\n",
    "    if template == 1: # template 1\n",
    "        eqns.loc[:,[\"q\", \"m\", \"g\",]] = eqns.loc[:,\"Equation\"].apply(lambda x: [y[y.index(\"= \")+2:] for y in x.split(\";\")] ).to_list()\n",
    "        eqns[\"gr\"] = eqns[\"g\"].apply(lambda x: x.replace(\"#1\", \"F\").replace(\"#2\", \"C\") )\n",
    "    elif template == 2: # template 2\n",
    "        eqns.loc[:,[\"q\", \"m\", \"g\", \"h\"]] = eqns.loc[:,\"Equation\"].apply(lambda x: [y[y.index(\"= \")+2:] for y in x.split(\";\")] ).to_list()\n",
    "        eqns[\"h\"] = eqns[\"h\"].apply(lambda x: x.replace(\"#1\", \"F\") )\n",
    "        eqns[\"gr\"] = eqns.loc[:,[\"g\", \"h\"]].apply(lambda x: x.iloc[0].replace(\"#1\", \"(C*({}))\".format(x.iloc[1])), axis=1 )\n",
    "    if template in [1,2]:\n",
    "        eqns[\"ad\"] = eqns.loc[:,[\"q\", \"m\"]].apply(lambda x: \"{}/({}+U**{})\".format(x.iloc[0], x.iloc[0], x.iloc[1],) , axis=1 )\n",
    "        eqns[\"Equation\"] = eqns.loc[:,[\"ad\", \"gr\"]].apply(lambda x: \"{}*{}\".format(x.iloc[0], x.iloc[1],) , axis=1 )\n",
    "    eqns = eqns[\"Equation\"]\n",
    "    \n",
    "    data = pd.read_csv(\"{}/{}.csv\".format(datalocation, name), )\n",
    "    \n",
    "    exprs, Kxprs, csts_counts, RSSs = [], [], [], []\n",
    "    for i, expr in enumerate(eqns):\n",
    "        expr = simplify(parse_expr(expr, symbols_dict))\n",
    "        exprs.append(expr)\n",
    "        csts_count, Kxpr = count_parameters(expr, Kxpr=True)\n",
    "        csts_counts.append( csts_count ) # count constants in each model\n",
    "        Kxprs.append( Kxpr )\n",
    "        # eval error\n",
    "        rho_hats = data[[\"C\", \"n\", \"F\", \"U\"]].apply(lambda x: expr.evalf(subs = {C: x.iloc[0], n: x.iloc[1], F: x.iloc[2], U: x.iloc[3],}), axis=1).to_numpy(dtype=float)\n",
    "        RSSs.append( np.sum( (data[\"rho\"] - rho_hats)**2 ) )        \n",
    "    \n",
    "    eqns = pd.DataFrame({\"name\": name, \"template\": template, \"ct\": csts_counts, \"eq\": exprs, \"Kq\": Kxprs, \"Loss\": Loss, \"RSS\": RSSs, \"NNN\": data.shape[0], # number of data points\n",
    "                                         }, )\n",
    "    eqns[\"AIC\"] = eqns[\"NNN\"] * np.log( (eqns[\"RSS\"] / eqns[\"NNN\"]).to_numpy(dtype=float) ) + 2 * (eqns[\"ct\"] + 1) # 10.1016/j.idm.2019.12.010, p. 124\n",
    "    alleqns = eqns if f == 0 else pd.concat([alleqns, eqns,], axis = 0)\n",
    "#    eqns.to_csv(\"{}/sreq{}/template_{}_{}.csv\".format(cwd, series, template, name))\n",
    "alleqns.sort_values([\"name\", \"ct\", \"Loss\", \"template\"], inplace = True)\n",
    "alleqns.to_csv(\"{}/sreq/{}.csv\".format(cwd, code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RsBi0 (E. coli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"RsBi0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd2 = # location of the SR outputs\n",
    "data = pd.read_csv(\"{}/data/{}.csv\".format(cwd, name), )\n",
    "allfiles = []\n",
    "for root, dirs, files in os.walk(cwd2):\n",
    "    if \"test\" in root:\n",
    "        continue\n",
    "    for file in files:\n",
    "        if file == \"hall_of_fame.csv\":\n",
    "            allfiles.append(os.path.join(root, file))\n",
    "\n",
    "code = \"RsB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in allfiles:\n",
    "    if \"no_template\" in file:\n",
    "        file0 = file\n",
    "    elif \"template_1\" in file:\n",
    "        file1 = file\n",
    "    elif \"template_2\" in file:\n",
    "        file2 = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for template, file in enumerate([file0, file1, file2]):\n",
    "\n",
    "    eqns = pd.read_csv(file, index_col=False )\n",
    "    eqns[\"Equation\"] = eqns[\"Equation\"].apply(lambda x: x.replace(\"^\", \"**\") )\n",
    "    if template == 1:\n",
    "        eqns.loc[:,[\"q\", \"m\", \"g\",]] = eqns.loc[:,\"Equation\"].apply(lambda x: [y[y.index(\"= \")+2:] for y in x.split(\";\")] ).to_list()\n",
    "        eqns[\"gr\"] = eqns[\"g\"].apply(lambda x: x.replace(\"#1\", \"F\").replace(\"#2\", \"C1\").replace(\"#3\", \"C2\") )\n",
    "    elif template == 2: # template 2\n",
    "        eqns.loc[:,[\"q\", \"m\", \"g\", \"h1\", \"h2\"]] = eqns.loc[:,\"Equation\"].apply(lambda x: [y[y.index(\"= \")+2:] for y in x.split(\";\")] ).to_list()\n",
    "        eqns[\"h1\"] = eqns[\"h1\"].apply(lambda x: x.replace(\"#1\", \"F\") )\n",
    "        eqns[\"h2\"] = eqns[\"h2\"].apply(lambda x: x.replace(\"#1\", \"F\") )\n",
    "        eqns[\"gr\"] = eqns.loc[:,[\"g\", \"h1\", \"h2\"]].apply(lambda x: x.iloc[0].replace(\"#1\", \"(C1*({}))\".format(x.iloc[1])).replace(\"#2\", \"(C2*({}))\".format(x.iloc[2])), axis=1 )\n",
    "    if template in [1,2]:\n",
    "        eqns[\"ad\"] = eqns.loc[:,[\"q\", \"m\"]].apply(lambda x: \"{}/({}+U**{})\".format(x.iloc[0], x.iloc[0], x.iloc[1],) , axis=1 )\n",
    "        eqns[\"Equation\"] = eqns.loc[:,[\"ad\", \"gr\"]].apply(lambda x: \"{}*{}\".format(x.iloc[0], x.iloc[1],) , axis=1 )\n",
    "    Loss = eqns[\"Loss\"]\n",
    "    eqns = eqns[\"Equation\"]\n",
    "    \n",
    "    exprs, Kxprs, csts_counts, RSSs = [], [], [], []\n",
    "    for i, expr in enumerate(eqns):\n",
    "        expr = simplify(parse_expr(expr, symbols_dict))\n",
    "        exprs.append(expr)\n",
    "        csts_count, Kxpr = count_parameters(expr, Kxpr=True)\n",
    "        csts_counts.append( csts_count ) # count constants in each model\n",
    "        Kxprs.append( Kxpr )\n",
    "        # eval error\n",
    "        def evalexpr(x):\n",
    "            try:\n",
    "                return float(expr.evalf(subs = {C1: x.iloc[0], C2: x.iloc[1], n: x.iloc[2], F: x.iloc[3], U: x.iloc[4],}))\n",
    "            except:\n",
    "                return np.nan\n",
    "        rho_hats = data[[\"C1\", \"C2\", \"n\", \"F\", \"U\"]].apply(evalexpr, axis=1).to_numpy(dtype=float)\n",
    "        RSSs.append( np.nansum( (data[\"rho\"] - rho_hats)**2 ) )        \n",
    "    \n",
    "    eqns = pd.DataFrame({\"strn\": name, \"template\": template, \"ct\": csts_counts, \"eq\": exprs, \"Kq\": Kxprs, \"Loss\": Loss, \"RSS\": RSSs, \"NNN\": data.shape[0], # number of data points\n",
    "                                         }, )\n",
    "    eqns[\"AIC\"] = eqns[\"NNN\"] * np.log( (eqns[\"RSS\"] / eqns[\"NNN\"]).to_numpy(dtype=float) ) + 2 * (eqns[\"ct\"] + 1) # compute AIC following: 10.1016/j.idm.2019.12.010, p. 124\n",
    "    megaeqns = eqns if template == 0 else pd.concat([megaeqns, eqns], axis = 0)\n",
    "megaeqns.sort_values([\"strn\", \"ct\", \"template\"], inplace = True)\n",
    "megaeqns.to_csv(\"{}/sreq/{}.csv\".format(cwd, code,), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"{}/sreq/RsB.csv\".format(cwd,)\n",
    "data = pd.read_csv(location, index_col=False )\n",
    "data[\"eq\"] = data[\"eq\"].apply(lambda expr: simplify(parse_expr(expr, symbols_dict)))\n",
    "data[\"Kq\"] = data[\"Kq\"].apply(lambda expr: simplify(parse_expr(expr, symbols_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 17\n",
    "for idx in range(5*i, 5*(i+1) ):\n",
    "    print(data.index[idx])\n",
    "    display(data.loc[data.index[idx], \"Kq\"])\n",
    "    display(data.loc[data.index[idx], \"eq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 45\n",
    "annot = \"a*M12\"\n",
    "data.loc[j, \"annotation\"] = annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(location, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking and summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"{}/sreq/RsB.csv\".format(cwd,)\n",
    "alldata = pd.read_csv(location, index_col=False )\n",
    "data = alldata[alldata[\"annotation\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.loc[data.groupby(\"name\")[\"Loss\"].idxmin()][[\"name\", \"Loss\", \"annotation\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of model performance and interpretability for Rs0-datasets Fig. 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "y_formatter = ScalarFormatter(useOffset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"Rs0\"\n",
    "\n",
    "location = \"{}/sreq/{}.csv\".format(cwd, code)\n",
    "alldata = pd.read_csv(location, index_col=False )\n",
    "\n",
    "X = alldata[alldata[\"annotation\"].notna()].copy()\n",
    "X[\"colour\"] = X[\"annotation\"].apply(lambda x: (\"w\" if (\"L\" in x ) else \"r\" ) if \"M\" in x else \"b\" )\n",
    "X[\"edge\"] = X[\"annotation\"].apply(lambda x: \"w\" if x in [\"L\", \"M\", \"a*L\", \"a*M\", ] else \"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YYY = 4 # number of rows\n",
    "param_max = 11 # odd number for max number of parameters on x axis\n",
    "figsize = (8,5)\n",
    "strns = sorted([ 105, 1287, 1292, 1299, 1842, 1896, 1972, 1977, 2160, 2164, 2443, 2659, 3031, 3237,  403,    6] ,)\n",
    "\n",
    "fig = plt.figure(figsize=figsize, constrained_layout=True)\n",
    "gs = fig.add_gridspec(YYY, 4)\n",
    "fig.supxlabel(\"number of model parameters\")\n",
    "fig.supylabel(\"performance: coefficient of determination R2\")\n",
    "\n",
    "for i, strn in enumerate(strns):\n",
    "    name = code + \"i\" + str(strn)\n",
    "    ax = fig.add_subplot(gs[i % YYY, i // YYY])\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.set(xlim=(0.5, param_max + 0.5), xticks = 2 * np.arange(param_max // 2 + 1) + 1 if i % YYY == YYY - 1 else [], ylim=(0, 1), yticks = [0, 0.5, 1,]  if i // YYY == 3 else [], ylabel= \"{}\".format(strn), )\n",
    "    plt.setp(ax.get_yminorticklabels(), visible=False) # <--- Hide the minor ticks\n",
    "    ax.yaxis.set_major_formatter(y_formatter)\n",
    "\n",
    "    # scatter plot\n",
    "    for t, template in enumerate(alldata[\"template\"].unique()):\n",
    "        # all models\n",
    "        df = alldata[(alldata[\"name\"] == name) & (alldata[\"template\"] == t)]\n",
    "        ax.scatter(df[\"ct\"], 1 - df[\"Loss\"], c = \"k\", marker = [\"o\", \"v\", \"^\"][t], alpha = 0.05, s = 30, zorder = 1)\n",
    "        # biologically interpretable models\n",
    "        if name in X[\"name\"].unique():\n",
    "            df = X[(X[\"name\"] == name) & (X[\"template\"] == t)]\n",
    "            ax.scatter(df[\"ct\"], 1 - df[\"Loss\"], c = df[\"colour\"], edgecolor = df[\"edge\"], marker = [\"o\", \"v\", \"^\"][t], alpha = 0.6, s = 40, zorder = 2)\n",
    "\n",
    "# saving\n",
    "path = \"{}/plot/Pareto_{}.pdf\".format(cwd, code)\n",
    "plt.savefig(path, facecolor='w', edgecolor='w', transparent=False, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of model performance and interpretability for RsB dataset Fig. S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"RsB\"\n",
    "\n",
    "location = \"{}/sreq/{}.csv\".format(cwd, code)\n",
    "alldata = pd.read_csv(location, index_col=False )\n",
    "\n",
    "X = alldata[alldata[\"annotation\"].notna()].copy()\n",
    "X[\"colour\"] = X[\"annotation\"].apply(lambda x: (\"w\" if (\"L\" in x ) else \"r\" ) if \"M\" in x else \"b\" )\n",
    "X[\"edge\"] = X[\"annotation\"].apply(lambda x: \"w\" if x in [\"L\", \"M\", \"a*L\", \"a*M\", ] else \"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_dict = {\"a*L1\":      [4.5, 0.07, r\"$g_{\\rm max}S_1$\", 1],\n",
    "                   \"a*L1*L2\":   [0.7, 0.20, r\"$g_{\\rm max}S_1S_2$\", 1],\n",
    "                   \"a*(L1+L2)\": [0.7, 0.55, r\"$g_{\\rm max}(S_1+S_2)$\", 1],\n",
    "                   \"a*M1\":      [7.0, 0.30, r\"$g_{\\rm max} \\dfrac{S_1}{K+S_1}$\", 1],\n",
    "                   \"a*M1*M2\":   [8.5, 0.60, r\"$g_{\\rm max}\\dfrac{S_1}{K_1+S_1}\\times\\dfrac{S_2}{K_2+S_2}$\", 1],\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_max = 15 # odd number for max number of parameters on x axis\n",
    "figsize = (8,5)\n",
    "fig = plt.figure(figsize=figsize, constrained_layout=True)\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.set(xlim=(0.5, param_max + 0.5), xticks = 2 * np.arange(param_max // 2 + 1) + 1, ylim=(0, 1), yticks = [0, 0.2, 0.4, 0.6, 0.8, 1,],\n",
    "       xlabel = \"number of model parameters\", ylabel = \"performance: coefficient of determination R2\", )#title = r\"$E.$ $coli$ data\" )\n",
    "plt.setp(ax.get_yminorticklabels(), visible=False) # <--- Hide the minor ticks\n",
    "ax.yaxis.set_major_formatter(y_formatter)\n",
    "\n",
    "# scatter plot\n",
    "for t, template in enumerate(alldata[\"template\"].unique()):\n",
    "    # all models\n",
    "    df = alldata[alldata[\"template\"] == t]\n",
    "    ax.scatter(df[\"ct\"], 1 - df[\"Loss\"], c = \"k\", marker = [\"o\", \"v\", \"^\"][t], alpha = 0.15, s = 30, zorder = 2)\n",
    "    # biologically interpretable models\n",
    "    df = X[X[\"template\"] == t]\n",
    "    ax.scatter(df[\"ct\"], 1 - df[\"Loss\"], c = df[\"colour\"], edgecolor = df[\"edge\"], marker = [\"o\", \"v\", \"^\"][t], alpha = 0.6, s = 40, zorder = 3)\n",
    "for idx in X.index:\n",
    "    x, y, txt = X.loc[idx,[\"ct\", \"Loss\", \"annotation\",]]\n",
    "    txt = annotation_dict[txt]\n",
    "    ax.annotate(txt[2], xy=(x, 1-y), xytext=(txt[0], txt[1]), zorder=1,\n",
    "                arrowprops=dict(facecolor='black', width = 0.01, headwidth = 0, headlength = 1, alpha=0.15), \n",
    "                bbox=dict(alpha=0),)\n",
    "\n",
    "# saving\n",
    "path = \"{}/plot/Pareto_{}.pdf\".format(cwd, code)\n",
    "plt.savefig(path, facecolor='w', edgecolor='w', transparent=False, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
